{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names-shuffled.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pushp',\n",
       " 'aishwary',\n",
       " 'prahalan',\n",
       " 'adrija',\n",
       " 'ghanika',\n",
       " 'vibulan',\n",
       " 'kavinthran',\n",
       " 'priyaalen']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {c:i+1 for i, c in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {v:k for k, v in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pushp\n",
      "... --> p\n",
      "..p --> u\n",
      ".pu --> s\n",
      "pus --> h\n",
      "ush --> p\n",
      "shp --> .\n",
      "-----------\n",
      "aishwary\n",
      "... --> a\n",
      "..a --> i\n",
      ".ai --> s\n",
      "ais --> h\n",
      "ish --> w\n",
      "shw --> a\n",
      "hwa --> r\n",
      "war --> y\n",
      "ary --> .\n",
      "-----------\n",
      "prahalan\n",
      "... --> p\n",
      "..p --> r\n",
      ".pr --> a\n",
      "pra --> h\n",
      "rah --> a\n",
      "aha --> l\n",
      "hal --> a\n",
      "ala --> n\n",
      "lan --> .\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3 # context length: number of chars used to predict the next char\n",
    "X, Y = [], [] # inputs and labels\n",
    "\n",
    "for w in words[:3]:\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    for c in w + '.':\n",
    "        \n",
    "        print(f\"{''.join(itos[item] for item in context)} --> {c}\")\n",
    "\n",
    "        X.append(context)\n",
    "        Y.append(stoi[c])\n",
    "        context = context[1:] + [stoi[c]] # sliding the context by 1 character to right\n",
    "    print('-----------')\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24, 3]), torch.Size([24]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(1337101)\n",
    "\n",
    "C = torch.randn((27, 2), generator=g) # lookup table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C is the lookup table which will contain the embeddings for all 27 characters. It is a matrix of size 27x2.\n",
    "Meaning it contains embedding of lenght 2 for a character.\n",
    "\n",
    "How to get embedding of a character from C?\n",
    "\n",
    "There are 2 ways:\n",
    "- We can directly do C[i], where i is the integer corrosponding to a character e.g. 1 for a and 2 for b.\n",
    "- We can create a one hot encodding for a character and then multiply that 1x27 one hot encoding by matrix C.\n",
    "\n",
    "Both of these operations will result in an encoding of size 1x2 for a character because all encodings are for size 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2890, 0.7356])\n",
      "tensor([0.2890, 0.7356])\n"
     ]
    }
   ],
   "source": [
    "print(C[5]) # first method\n",
    "t = F.one_hot(torch.tensor(5), num_classes=27).float()\n",
    "print(t@C) # second method\n",
    "\n",
    "# both of these operations will result in same output. We'll choose the first method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to encode the complete X tensor which is of size [m, block_size].\n",
    "\n",
    "For explanation, let's take m=24 and blok_size=3. So X is of size [24, 3].\n",
    "\n",
    "PyTorch can do this directly by passing X to C like C[X]. This will result in an output of size [24, 3, 2].\n",
    "\n",
    "X contains 3 characters in all the 24 rows and all the characters have and embedding of size 2. Hence the size of output\n",
    "is [24, 3, 2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 3, 2])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6996, -0.1849],\n",
       "        [ 0.6996, -0.1849],\n",
       "        [ 0.6996, -0.1849]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X[0])\n",
    "C[X][0]\n",
    "\n",
    "# all 3 embeddings are same because all the characters are same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 3, 2])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "emb.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zoro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
